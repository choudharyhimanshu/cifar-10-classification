{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def reshape_img(img):\n",
    "    img = img.reshape((3,32*32))\n",
    "    v = np.zeros((32,32,3),dtype=np.uint8)\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            v[i][j][0] = img[0][i*32+j]\n",
    "            v[i][j][1] = img[1][i*32+j]\n",
    "            v[i][j][2] = img[2][i*32+j]  \n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "DATASET_DIR = \"cifar-10-batches-py/\"\n",
    "DATASET_FILES = [\"data_batch_1\",\"data_batch_2\",\"data_batch_3\",\"data_batch_4\",\"data_batch_5\"]\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "for file in DATASET_FILES:\n",
    "    data = unpickle(DATASET_DIR + file)\n",
    "    imgs.extend(data[\"data\"])\n",
    "    labels.extend(data[\"labels\"])\n",
    "    \n",
    "dataset = pd.DataFrame({'img': imgs, 'label': labels})\n",
    "dataset[\"img\"] = dataset.img.map(reshape_img)\n",
    "dataset.to_pickle(\"dataset/train.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "DATASET_DIR = \"cifar-10-batches-py/\"\n",
    "DATASET_FILES = [\"test_batch\"]\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "for file in DATASET_FILES:\n",
    "    data = unpickle(DATASET_DIR + file)\n",
    "    imgs.extend(data[\"data\"])\n",
    "    labels.extend(data[\"labels\"])\n",
    "    \n",
    "dataset = pd.DataFrame({'img': imgs, 'label': labels})\n",
    "dataset[\"img\"] = dataset.img.map(reshape_img)\n",
    "dataset.to_pickle(\"dataset/test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = \"dataset/\"\n",
    "DATASET_FILE = \"train.pkl\"\n",
    "\n",
    "# LABELS = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "LABELS = ['airplane','automobile','bird','cat','frog','horse','ship','truck']\n",
    "\n",
    "dataset = pd.read_pickle(DATASET_DIR + DATASET_FILE)\n",
    "dataset = dataset.sample(30000,random_state=7)\n",
    "dataset = dataset[dataset.label != 4]\n",
    "dataset = dataset[dataset.label != 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(dataset,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from sklearn.svm import LinearSVC,SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1). Using HOG descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print \"Computing descriptors for train set\"\n",
    "X_train = []\n",
    "for img in dataset_train.img.values:\n",
    "    X_train.append(hog(color.rgb2gray(img)))\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "print \"Computing descriptors for test set\"\n",
    "X_test = []\n",
    "for img in dataset_test.img.values:\n",
    "    X_test.append(hog(color.rgb2gray(img)))\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_train = dataset_train.label.values\n",
    "y_test = dataset_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2). Using Kmeans clustered BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DICT_SIZE = 100\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 10)\n",
    "search_params = dict(checks=20)\n",
    "\n",
    "bow_trainer = cv2.BOWKMeansTrainer(DICT_SIZE)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# matcher = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
    "transformer = cv2.BOWImgDescriptorExtractor(sift,matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute and dump Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i,row in dataset.iterrows():\n",
    "    kp, des = sift.detectAndCompute(cv2.cvtColor(row.img,cv2.COLOR_BGR2GRAY),None)\n",
    "#     kp, des = sift.detectAndCompute(row.img,None)\n",
    "    if des != None:\n",
    "        bow_trainer.add(des)\n",
    "    else:\n",
    "        print \"No features found in image: \" + str(i)\n",
    "\n",
    "print \"Clustering features..\"\n",
    "vocab = bow_trainer.cluster()\n",
    "# cPickle.dump(vocab,file(\"dataset/vocab.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = cPickle.load(file(\"dataset/vocab.pkl\",\"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get BOW vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transformer.setVocabulary(vocab)\n",
    "\n",
    "print \"Computing train set BOW vectors..\"\n",
    "X_train = []\n",
    "for img in dataset_train.img.values:\n",
    "    v = transformer.compute(img,sift.detect(img,None))\n",
    "    if v != None:\n",
    "        X_train.append(np.array(v[0]))\n",
    "    else:\n",
    "        X_train.append(np.zeros(DICT_SIZE))\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "print \"Computing test set BOW vectors..\"\n",
    "X_test = []\n",
    "for img in dataset_test.img.values:\n",
    "    v = transformer.compute(img,sift.detect(img,None))\n",
    "    if v!= None:\n",
    "        X_test.append(np.array(v[0]))\n",
    "    else:\n",
    "        X_test.append(np.zeros(DICT_SIZE))\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_train = dataset_train.label.values\n",
    "y_test = dataset_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LinearSVC(verbose=1)\n",
    "# model = SVC(verbose=1)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(preds,y_test)\n",
    "df_cm = pd.DataFrame(cm, index = LABELS,\n",
    "                  columns = LABELS)\n",
    "sn.heatmap(df_cm,annot=True,fmt=\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,Convolution2D,MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for v in dataset_train.img.values:\n",
    "    X_train.append(np.array(v))\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "X_test = []\n",
    "for v in dataset_test.img.values:\n",
    "    X_test.append(np.array(v))\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_train = to_categorical(dataset_train.label.values)\n",
    "y_test = to_categorical(dataset_test.label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "L_RATE = 0.01\n",
    "DECAY = L_RATE/EPOCHS\n",
    "\n",
    "sgd = SGD(lr=L_RATE, momentum=0.9, decay=DECAY, nesterov=False)\n",
    "\n",
    "# Create Keras model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', activation='relu',input_shape=(32,32,3)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid', activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='valid', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, nb_epoch=25,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for pred in model.predict(X_test):\n",
    "    preds.append(pred.argmax())\n",
    "    \n",
    "y_test_labels = []\n",
    "for y in y_test:\n",
    "    y_test_labels.append(y.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(preds,y_test_labels)\n",
    "df_cm = pd.DataFrame(cm, index = LABELS,\n",
    "                  columns = LABELS)\n",
    "sn.heatmap(df_cm,annot=True,fmt=\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vr_project]",
   "language": "python",
   "name": "conda-env-vr_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
