{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def reshape_img(img):\n",
    "    img = img.reshape((3,32*32))\n",
    "    v = np.zeros((32,32,3),dtype=np.uint8)\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            v[i][j][0] = img[0][i*32+j]\n",
    "            v[i][j][1] = img[1][i*32+j]\n",
    "            v[i][j][2] = img[2][i*32+j]  \n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "DATASET_DIR = \"cifar-10-batches-py/\"\n",
    "DATASET_FILES = [\"data_batch_1\",\"data_batch_2\",\"data_batch_3\",\"data_batch_4\",\"data_batch_5\"]\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "for file in DATASET_FILES:\n",
    "    data = unpickle(DATASET_DIR + file)\n",
    "    imgs.extend(data[\"data\"])\n",
    "    labels.extend(data[\"labels\"])\n",
    "    \n",
    "dataset = pd.DataFrame({'img': imgs, 'label': labels})\n",
    "dataset[\"img\"] = dataset.img.map(reshape_img)\n",
    "dataset.to_pickle(\"dataset/train.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "DATASET_DIR = \"cifar-10-batches-py/\"\n",
    "DATASET_FILES = [\"test_batch\"]\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "for file in DATASET_FILES:\n",
    "    data = unpickle(DATASET_DIR + file)\n",
    "    imgs.extend(data[\"data\"])\n",
    "    labels.extend(data[\"labels\"])\n",
    "    \n",
    "dataset = pd.DataFrame({'img': imgs, 'label': labels})\n",
    "dataset[\"img\"] = dataset.img.map(reshape_img)\n",
    "dataset.to_pickle(\"dataset/test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = \"dataset/\"\n",
    "DATASET_FILE = \"train.pkl\"\n",
    "\n",
    "LABELS = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "# LABELS = ['airplane','automobile','bird','cat','deer','frog','horse','ship','truck']\n",
    "\n",
    "dataset = pd.read_pickle(DATASET_DIR + DATASET_FILE)\n",
    "dataset = dataset.sample(3000,random_state=7)\n",
    "# dataset = dataset[dataset.label != 3]\n",
    "# dataset = dataset[dataset.label != 5]\n",
    "\n",
    "SUFFIX = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(dataset,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1). Using HOG descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print \"Computing descriptors for train set\"\n",
    "X_train = []\n",
    "for img in dataset_train.img.values:\n",
    "    X_train.append(hog(color.rgb2gray(img)))\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "print \"Computing descriptors for test set\"\n",
    "X_test = []\n",
    "for img in dataset_test.img.values:\n",
    "    X_test.append(hog(color.rgb2gray(img)))\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_train = dataset_train.label.values\n",
    "y_test = dataset_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2). Using Kmeans clustered BOW"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# DICT_SIZE = 100\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 10)\n",
    "search_params = dict(checks=20)\n",
    "\n",
    "bow_trainer = cv2.BOWKMeansTrainer(DICT_SIZE)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# matcher = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
    "transformer = cv2.BOWImgDescriptorExtractor(sift,matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute and dump Vocab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "for i,row in dataset.iterrows():\n",
    "    kp, des = sift.detectAndCompute(cv2.cvtColor(row.img,cv2.COLOR_BGR2GRAY),None)\n",
    "#     kp, des = sift.detectAndCompute(row.img,None)\n",
    "    if des != None:\n",
    "        bow_trainer.add(des)\n",
    "    else:\n",
    "        print \"No features found in image: \" + str(i)\n",
    "\n",
    "print \"Clustering features..\"\n",
    "vocab = bow_trainer.cluster()\n",
    "# cPickle.dump(vocab,file(\"dataset/vocab.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Vocab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vocab = cPickle.load(file(\"dataset/vocab.pkl\",\"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get BOW vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "\n",
    "transformer.setVocabulary(vocab)\n",
    "\n",
    "print \"Computing train set BOW vectors..\"\n",
    "X_train = []\n",
    "for img in dataset_train.img.values:\n",
    "    v = transformer.compute(img,sift.detect(img,None))\n",
    "    if v != None:\n",
    "        X_train.append(np.array(v[0]))\n",
    "    else:\n",
    "        X_train.append(np.zeros(DICT_SIZE))\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "print \"Computing test set BOW vectors..\"\n",
    "X_test = []\n",
    "for img in dataset_test.img.values:\n",
    "    v = transformer.compute(img,sift.detect(img,None))\n",
    "    if v!= None:\n",
    "        X_test.append(np.array(v[0]))\n",
    "    else:\n",
    "        X_test.append(np.zeros(DICT_SIZE))\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_train = dataset_train.label.values\n",
    "y_test = dataset_test.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init and Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LinearSVC(multi_class='crammer_singer',verbose=1)\n",
    "# model = SVC(decision_function_shape='ova',kernel='linear',verbose=True)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.score(X_test,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"output/score\"+str(SUFFIX)+\".txt\",'w+')\n",
    "f.write(\"%s\\n\\n\" % str(score))\n",
    "f.write(classification_report(y_test,preds,target_names=LABELS))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(preds,y_test)\n",
    "df_cm = pd.DataFrame(cm, index = LABELS,\n",
    "                  columns = LABELS)\n",
    "sn.heatmap(df_cm,annot=True,fmt=\"\")\n",
    "plt.savefig('output/fig'+str(SUFFIX)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'Predicted': preds,'Actual': y_test})\n",
    "out.to_csv(\"output/preds_\"+str(SUFFIX)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y_test,preds,target_names=LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vr_project]",
   "language": "python",
   "name": "conda-env-vr_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
